\section{Related Work}
\label{sec:related_work}

\para{Internal language representations in LLMs.}
A growing body of work investigates how multilingual models internally process non-English inputs. \citet{wendler2024llamas} applied logit lens analysis to Llama-2 and identified a three-phase processing pipeline: early layers build language-agnostic features, middle layers operate in an English-biased concept space, and final layers decode to the target language. \citet{zhang2024multilingual} proposed the Multilingual Workflow (MWork) hypothesis and developed PLND (Parallel Language-specific Neuron Detection) to identify language-specific neurons, finding that self-attention layers in middle layers decrease activity (English reasoning) while feed-forward neurons remain consistent (multilingual knowledge storage). These mechanistic findings establish the theoretical basis for our behavioral investigation: if models reason internally in English, then explicitly translating to English should help.

\para{Self-translation and cross-lingual prompting.}
Several strategies exploit the English-biased internals of LLMs to improve multilingual performance. \citet{etxaniz2023multilingual} introduced the self-translate approach, showing that using the LLM itself to translate inputs to English before task-solving consistently improved accuracy by 2--3.5 points on XGLM and Llama models. \citet{huang2023languages} proposed Cross-Lingual-Thought (XLT) prompting, achieving over 10-point improvements on \mgsm and introducing the \demscore to measure cross-language equity. \citet{shi2022language} demonstrated that English \chainofthought prompting works effectively across languages, outperforming native-language reasoning---a finding that motivated the \mgsm benchmark. Our work tests whether these English-pivoting benefits persist in models trained two to three years later.

\para{Multilingual benchmarking of LLMs.}
\citet{ahuja2023mega} provided the first comprehensive multilingual evaluation of generative LLMs, benchmarking GPT-3.5, GPT-4, and BLOOMZ across 16 datasets and 70 languages, finding significant English--non-English gaps of 10--30\% especially for low-resource languages. \citet{bandarkar2023belebele} introduced the \belebele benchmark with parallel reading comprehension passages in 122 language variants, enabling controlled cross-lingual comparison. \citet{hu2020xtreme} established XTREME as a foundational multilingual multi-task benchmark covering 9 tasks and 40 languages. Our work updates these evaluations to 2025--2026 frontier models and combines benchmark performance with prompting strategy analysis.

\para{Chain-of-thought reasoning.}
\citet{wei2022chain} showed that \chainofthought prompting dramatically improves reasoning in LLMs. This finding is directly relevant to our work because several English-pivoting strategies (\eg self-translate, English CoT) confound language effects with reasoning effects: they add step-by-step reasoning that is absent from direct inference. We explicitly control for this confound in our experimental design and analysis.
